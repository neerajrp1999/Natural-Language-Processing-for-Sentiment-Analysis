{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing for Sentiment Analysis"
      ],
      "metadata": {
        "id": "S69bI5lU-9rO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing required libraries</br>\n",
        "    a) nltk</br>\n",
        "    b) re</br>\n",
        "    c) numpy</br>\n",
        "    d) pandas</br>\n",
        "    e) sklearn</br>\n",
        "    f) tensorflow</br>"
      ],
      "metadata": {
        "id": "rfG5GN4NACeU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fql5V3nlYE0-",
        "outputId": "0986ce1a-54f5-4f51-86c3-06db2e23c028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. load data\n"
      ],
      "metadata": {
        "id": "sKEF1Dx1BUiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step: Data load\n",
        "data = pd.read_csv(\"hate.csv\", encoding=\"windows-1252\")"
      ],
      "metadata": {
        "id": "HfBVpl_QBOpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data Preprocessing</br>\n",
        "    In the preprocess_text method, we convert all text to lowercase, remove the stop words, Tokenize data, apply stemming and do Label Encoder."
      ],
      "metadata": {
        "id": "IzqY0a_ABbvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step: Data Preprocessing\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove non-alphanumeric characters and extra whitespaces\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Apply stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    # Join stemmed tokens back into a string\n",
        "    preprocessed_text = ' '.join(stemmed_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to the 'comment' column\n",
        "data['comment'] = data['comment'].apply(preprocess_text)\n",
        "\n",
        "# Step : Tokenize the data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['comment'])\n",
        "\n",
        "X = tokenizer.texts_to_sequences(data['comment'])\n",
        "X = pad_sequences(X, maxlen=100)  # Adjust maxlen as needed\n",
        "y = data['label']\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "jQpxdkIpBaJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Split the dataset"
      ],
      "metadata": {
        "id": "x2PJgSzwFKkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "qD8PBmjXHjeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Defining Model"
      ],
      "metadata": {
        "id": "HSTNy6uEHofK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step : Define the TensorFlow model (LSTM)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=100),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # 3 output classes: positive, negative, neutral\n",
        "])"
      ],
      "metadata": {
        "id": "oHRQx55gIFWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compile the model"
      ],
      "metadata": {
        "id": "MSu9-29-ITE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bz1xEGqQIVw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Start Model Training"
      ],
      "metadata": {
        "id": "hA3h0nHNIYz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step : Model Training\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvglKxyDIhhX",
        "outputId": "1e48a54c-0930-4883-ff13-93343fe2cda6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "810/810 [==============================] - 75s 90ms/step - loss: 0.6386 - accuracy: 0.6198 - val_loss: 0.5773 - val_accuracy: 0.6816\n",
            "Epoch 2/100\n",
            "810/810 [==============================] - 73s 91ms/step - loss: 0.5121 - accuracy: 0.7346 - val_loss: 0.5725 - val_accuracy: 0.6743\n",
            "Epoch 3/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.4195 - accuracy: 0.7966 - val_loss: 0.6406 - val_accuracy: 0.6788\n",
            "Epoch 4/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.3380 - accuracy: 0.8424 - val_loss: 0.7405 - val_accuracy: 0.6778\n",
            "Epoch 5/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.2696 - accuracy: 0.8765 - val_loss: 0.8759 - val_accuracy: 0.6625\n",
            "Epoch 6/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.2143 - accuracy: 0.9038 - val_loss: 0.9851 - val_accuracy: 0.6740\n",
            "Epoch 7/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.1682 - accuracy: 0.9256 - val_loss: 1.2205 - val_accuracy: 0.6597\n",
            "Epoch 8/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.1357 - accuracy: 0.9416 - val_loss: 1.3315 - val_accuracy: 0.6486\n",
            "Epoch 9/100\n",
            "810/810 [==============================] - 72s 88ms/step - loss: 0.1075 - accuracy: 0.9553 - val_loss: 1.4685 - val_accuracy: 0.6451\n",
            "Epoch 10/100\n",
            "810/810 [==============================] - 72s 88ms/step - loss: 0.0906 - accuracy: 0.9637 - val_loss: 1.6785 - val_accuracy: 0.6465\n",
            "Epoch 11/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0717 - accuracy: 0.9719 - val_loss: 1.8955 - val_accuracy: 0.6545\n",
            "Epoch 12/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0601 - accuracy: 0.9766 - val_loss: 2.0215 - val_accuracy: 0.6528\n",
            "Epoch 13/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0527 - accuracy: 0.9785 - val_loss: 2.0413 - val_accuracy: 0.6458\n",
            "Epoch 14/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0441 - accuracy: 0.9828 - val_loss: 2.2461 - val_accuracy: 0.6424\n",
            "Epoch 15/100\n",
            "810/810 [==============================] - 71s 87ms/step - loss: 0.0400 - accuracy: 0.9843 - val_loss: 2.3151 - val_accuracy: 0.6420\n",
            "Epoch 16/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0371 - accuracy: 0.9855 - val_loss: 2.4461 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0334 - accuracy: 0.9872 - val_loss: 2.4437 - val_accuracy: 0.6372\n",
            "Epoch 18/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0334 - accuracy: 0.9875 - val_loss: 2.4835 - val_accuracy: 0.6424\n",
            "Epoch 19/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0268 - accuracy: 0.9888 - val_loss: 2.5355 - val_accuracy: 0.6285\n",
            "Epoch 20/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0236 - accuracy: 0.9901 - val_loss: 2.5596 - val_accuracy: 0.6517\n",
            "Epoch 21/100\n",
            "810/810 [==============================] - 73s 91ms/step - loss: 0.0212 - accuracy: 0.9911 - val_loss: 2.5627 - val_accuracy: 0.6406\n",
            "Epoch 22/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0212 - accuracy: 0.9910 - val_loss: 2.7530 - val_accuracy: 0.6458\n",
            "Epoch 23/100\n",
            "810/810 [==============================] - 74s 92ms/step - loss: 0.0188 - accuracy: 0.9919 - val_loss: 2.5892 - val_accuracy: 0.6378\n",
            "Epoch 24/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0163 - accuracy: 0.9930 - val_loss: 3.0294 - val_accuracy: 0.6455\n",
            "Epoch 25/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0171 - accuracy: 0.9932 - val_loss: 2.8705 - val_accuracy: 0.6427\n",
            "Epoch 26/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0147 - accuracy: 0.9937 - val_loss: 2.9416 - val_accuracy: 0.6378\n",
            "Epoch 27/100\n",
            "810/810 [==============================] - 74s 92ms/step - loss: 0.0152 - accuracy: 0.9931 - val_loss: 2.9647 - val_accuracy: 0.6576\n",
            "Epoch 28/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0143 - accuracy: 0.9937 - val_loss: 2.9530 - val_accuracy: 0.6410\n",
            "Epoch 29/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0151 - accuracy: 0.9934 - val_loss: 3.0421 - val_accuracy: 0.6406\n",
            "Epoch 30/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0139 - accuracy: 0.9940 - val_loss: 3.0497 - val_accuracy: 0.6413\n",
            "Epoch 31/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0094 - accuracy: 0.9952 - val_loss: 3.1751 - val_accuracy: 0.6399\n",
            "Epoch 32/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0088 - accuracy: 0.9953 - val_loss: 3.2512 - val_accuracy: 0.6486\n",
            "Epoch 33/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0071 - accuracy: 0.9961 - val_loss: 3.3309 - val_accuracy: 0.6361\n",
            "Epoch 34/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0072 - accuracy: 0.9959 - val_loss: 3.4262 - val_accuracy: 0.6434\n",
            "Epoch 35/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0096 - accuracy: 0.9951 - val_loss: 3.1559 - val_accuracy: 0.6424\n",
            "Epoch 36/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0214 - accuracy: 0.9916 - val_loss: 3.0253 - val_accuracy: 0.6444\n",
            "Epoch 37/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0170 - accuracy: 0.9931 - val_loss: 2.8036 - val_accuracy: 0.6413\n",
            "Epoch 38/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 2.9895 - val_accuracy: 0.6434\n",
            "Epoch 39/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0063 - accuracy: 0.9960 - val_loss: 3.0071 - val_accuracy: 0.6417\n",
            "Epoch 40/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0072 - accuracy: 0.9959 - val_loss: 3.1357 - val_accuracy: 0.6365\n",
            "Epoch 41/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0079 - accuracy: 0.9958 - val_loss: 3.1580 - val_accuracy: 0.6476\n",
            "Epoch 42/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0076 - accuracy: 0.9960 - val_loss: 3.0888 - val_accuracy: 0.6521\n",
            "Epoch 43/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0117 - accuracy: 0.9950 - val_loss: 3.1465 - val_accuracy: 0.6444\n",
            "Epoch 44/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0086 - accuracy: 0.9953 - val_loss: 3.1072 - val_accuracy: 0.6330\n",
            "Epoch 45/100\n",
            "810/810 [==============================] - 74s 92ms/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 2.8334 - val_accuracy: 0.6410\n",
            "Epoch 46/100\n",
            "810/810 [==============================] - 75s 92ms/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 3.1330 - val_accuracy: 0.6392\n",
            "Epoch 47/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 3.0960 - val_accuracy: 0.6521\n",
            "Epoch 48/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 3.0683 - val_accuracy: 0.6424\n",
            "Epoch 49/100\n",
            "810/810 [==============================] - 74s 92ms/step - loss: 0.0062 - accuracy: 0.9961 - val_loss: 3.2037 - val_accuracy: 0.6385\n",
            "Epoch 50/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0075 - accuracy: 0.9961 - val_loss: 3.0655 - val_accuracy: 0.6424\n",
            "Epoch 51/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0083 - accuracy: 0.9960 - val_loss: 2.9543 - val_accuracy: 0.6424\n",
            "Epoch 52/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0080 - accuracy: 0.9960 - val_loss: 3.0853 - val_accuracy: 0.6451\n",
            "Epoch 53/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0078 - accuracy: 0.9959 - val_loss: 3.0476 - val_accuracy: 0.6486\n",
            "Epoch 54/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0085 - accuracy: 0.9960 - val_loss: 2.8911 - val_accuracy: 0.6448\n",
            "Epoch 55/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0086 - accuracy: 0.9961 - val_loss: 2.9440 - val_accuracy: 0.6486\n",
            "Epoch 56/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0079 - accuracy: 0.9958 - val_loss: 2.8823 - val_accuracy: 0.6410\n",
            "Epoch 57/100\n",
            "810/810 [==============================] - 73s 91ms/step - loss: 0.0052 - accuracy: 0.9965 - val_loss: 3.0624 - val_accuracy: 0.6431\n",
            "Epoch 58/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 3.0700 - val_accuracy: 0.6410\n",
            "Epoch 59/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0061 - accuracy: 0.9968 - val_loss: 2.9910 - val_accuracy: 0.6392\n",
            "Epoch 60/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0086 - accuracy: 0.9957 - val_loss: 2.9933 - val_accuracy: 0.6427\n",
            "Epoch 61/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0081 - accuracy: 0.9959 - val_loss: 2.9031 - val_accuracy: 0.6441\n",
            "Epoch 62/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0070 - accuracy: 0.9959 - val_loss: 3.0819 - val_accuracy: 0.6406\n",
            "Epoch 63/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0054 - accuracy: 0.9965 - val_loss: 2.9734 - val_accuracy: 0.6448\n",
            "Epoch 64/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0048 - accuracy: 0.9966 - val_loss: 3.0398 - val_accuracy: 0.6434\n",
            "Epoch 65/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0047 - accuracy: 0.9970 - val_loss: 3.0698 - val_accuracy: 0.6420\n",
            "Epoch 66/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0041 - accuracy: 0.9971 - val_loss: 3.1579 - val_accuracy: 0.6368\n",
            "Epoch 67/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0042 - accuracy: 0.9969 - val_loss: 3.1354 - val_accuracy: 0.6399\n",
            "Epoch 68/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0041 - accuracy: 0.9970 - val_loss: 3.2398 - val_accuracy: 0.6354\n",
            "Epoch 69/100\n",
            "810/810 [==============================] - 73s 89ms/step - loss: 0.0040 - accuracy: 0.9970 - val_loss: 3.2557 - val_accuracy: 0.6382\n",
            "Epoch 70/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0039 - accuracy: 0.9970 - val_loss: 3.3920 - val_accuracy: 0.6410\n",
            "Epoch 71/100\n",
            "810/810 [==============================] - 73s 91ms/step - loss: 0.0084 - accuracy: 0.9958 - val_loss: 3.0570 - val_accuracy: 0.6333\n",
            "Epoch 72/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 2.8807 - val_accuracy: 0.6389\n",
            "Epoch 73/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0055 - accuracy: 0.9965 - val_loss: 2.9857 - val_accuracy: 0.6427\n",
            "Epoch 74/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0042 - accuracy: 0.9972 - val_loss: 3.1274 - val_accuracy: 0.6438\n",
            "Epoch 75/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0037 - accuracy: 0.9971 - val_loss: 3.1642 - val_accuracy: 0.6420\n",
            "Epoch 76/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0041 - accuracy: 0.9969 - val_loss: 3.1688 - val_accuracy: 0.6399\n",
            "Epoch 77/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0041 - accuracy: 0.9968 - val_loss: 3.2155 - val_accuracy: 0.6455\n",
            "Epoch 78/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0037 - accuracy: 0.9970 - val_loss: 3.2656 - val_accuracy: 0.6424\n",
            "Epoch 79/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0037 - accuracy: 0.9967 - val_loss: 3.2934 - val_accuracy: 0.6410\n",
            "Epoch 80/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0037 - accuracy: 0.9967 - val_loss: 3.3520 - val_accuracy: 0.6427\n",
            "Epoch 81/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0037 - accuracy: 0.9970 - val_loss: 3.3758 - val_accuracy: 0.6441\n",
            "Epoch 82/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0044 - accuracy: 0.9965 - val_loss: 3.2071 - val_accuracy: 0.6472\n",
            "Epoch 83/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0109 - accuracy: 0.9951 - val_loss: 2.9540 - val_accuracy: 0.6531\n",
            "Epoch 84/100\n",
            "810/810 [==============================] - 73s 91ms/step - loss: 0.0085 - accuracy: 0.9962 - val_loss: 2.9642 - val_accuracy: 0.6417\n",
            "Epoch 85/100\n",
            "810/810 [==============================] - 75s 92ms/step - loss: 0.0062 - accuracy: 0.9965 - val_loss: 2.8121 - val_accuracy: 0.6326\n",
            "Epoch 86/100\n",
            "810/810 [==============================] - 73s 91ms/step - loss: 0.0050 - accuracy: 0.9966 - val_loss: 2.9382 - val_accuracy: 0.6372\n",
            "Epoch 87/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0037 - accuracy: 0.9971 - val_loss: 3.0472 - val_accuracy: 0.6375\n",
            "Epoch 88/100\n",
            "810/810 [==============================] - 74s 92ms/step - loss: 0.0036 - accuracy: 0.9971 - val_loss: 3.1069 - val_accuracy: 0.6451\n",
            "Epoch 89/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0037 - accuracy: 0.9970 - val_loss: 3.1700 - val_accuracy: 0.6441\n",
            "Epoch 90/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0035 - accuracy: 0.9975 - val_loss: 3.2662 - val_accuracy: 0.6438\n",
            "Epoch 91/100\n",
            "810/810 [==============================] - 80s 98ms/step - loss: 0.0034 - accuracy: 0.9973 - val_loss: 3.2884 - val_accuracy: 0.6427\n",
            "Epoch 92/100\n",
            "810/810 [==============================] - 72s 89ms/step - loss: 0.0035 - accuracy: 0.9970 - val_loss: 3.3534 - val_accuracy: 0.6420\n",
            "Epoch 93/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0035 - accuracy: 0.9972 - val_loss: 3.3832 - val_accuracy: 0.6420\n",
            "Epoch 94/100\n",
            "810/810 [==============================] - 74s 92ms/step - loss: 0.0035 - accuracy: 0.9969 - val_loss: 3.4439 - val_accuracy: 0.6434\n",
            "Epoch 95/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0040 - accuracy: 0.9970 - val_loss: 3.4786 - val_accuracy: 0.6417\n",
            "Epoch 96/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0097 - accuracy: 0.9956 - val_loss: 3.2537 - val_accuracy: 0.6469\n",
            "Epoch 97/100\n",
            "810/810 [==============================] - 74s 91ms/step - loss: 0.0063 - accuracy: 0.9966 - val_loss: 3.1022 - val_accuracy: 0.6410\n",
            "Epoch 98/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0039 - accuracy: 0.9973 - val_loss: 3.1799 - val_accuracy: 0.6441\n",
            "Epoch 99/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0042 - accuracy: 0.9973 - val_loss: 3.1096 - val_accuracy: 0.6392\n",
            "Epoch 100/100\n",
            "810/810 [==============================] - 73s 90ms/step - loss: 0.0034 - accuracy: 0.9973 - val_loss: 3.1735 - val_accuracy: 0.6413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Evaluation\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "# Convert predictions back to original labels\n",
        "predicted_labels = label_encoder.inverse_transform(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3bApMJKL9ko",
        "outputId": "0008fb1e-e868-4ca0-e9e0-ab379f982db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 9s 21ms/step - loss: 3.2544 - accuracy: 0.6257\n",
            "386/386 [==============================] - 8s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN7A92_HUZL3",
        "outputId": "4ab6d6c9-23fe-4e36-d7bd-5ce28e4fff18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Overall Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "MiPodv3P-mrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f735460e-2133-4728-951a-91a9eeb19cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6257290840148926\n",
            "Test Loss: 3.2544116973876953\n",
            "Overall Accuracy: 0.6257290991574854\n",
            "Precision: 0.6249980524176595\n",
            "Recall: 0.6257290991574854\n",
            "F1-score: 0.6253528704545208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}